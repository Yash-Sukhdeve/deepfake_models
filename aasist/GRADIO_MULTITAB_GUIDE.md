# Comprehensive Deepfake Detection System - Multi-Tab Interface Guide

## Overview

This multi-tab Gradio interface provides a complete research and production environment for audio deepfake detection using AASIST and XLS-R+SLS models.

**File**: `gradio_app_multitab.py`

## Quick Start

```bash
# Basic launch (local access only)
python gradio_app_multitab.py

# Create public share link
python gradio_app_multitab.py --share

# Custom port
python gradio_app_multitab.py --port 8080

# External access (all network interfaces)
python gradio_app_multitab.py --server_name 0.0.0.0 --port 7860
```

Access the interface at: `http://127.0.0.1:7860`

## Tab-by-Tab Functionality

### Tab 1: üéôÔ∏è Single Audio Detection

**Purpose**: Analyze individual audio files or microphone recordings

**Features**:
- Upload audio files (WAV, FLAC, MP3, OGG, M4A, etc.)
- Record audio directly from microphone
- Select model (AASIST, AASIST-L, XLS-R+SLS)
- Choose processing device (CUDA/CPU)

**Outputs**:
- **Prediction**: Bonafide (real) or Spoof (fake)
- **Confidence**: Overall confidence percentage
- **Scores**: Detailed bonafide and spoof scores
- **Visualizations**:
  - Prediction bar chart
  - Audio waveform
  - Spectrogram (frequency analysis)
  - Chunk analysis (for long audio)

**Use Cases**:
- Quick verification of suspicious audio
- Real-time microphone recording analysis
- Educational demonstrations
- Prototype testing

**Example Workflow**:
1. Click "Upload Audio or Record"
2. Select audio file or record from microphone
3. Choose model from dropdown
4. Click "üîç Analyze Audio"
5. Review results and visualizations

---

### Tab 2: üì¶ Batch Processing

**Purpose**: Process multiple audio files simultaneously

**Features**:
- Multi-file upload (drag & drop supported)
- Parallel processing with progress tracking
- Automatic CSV export
- Summary statistics and distribution charts

**Outputs**:
- **Summary**: Total files, bonafide/spoof counts, percentages
- **Results Table**: Per-file predictions with confidence scores
- **Distribution Pie Chart**: Visual breakdown
- **CSV File**: Exportable results in `batch_results/batch_results_TIMESTAMP.csv`

**Use Cases**:
- Evaluating audio datasets
- Quality control for speech databases
- Forensic batch analysis
- Research dataset preparation

**Example Workflow**:
1. Click "Upload Multiple Audio Files"
2. Select multiple audio files (can drag & drop)
3. Choose model
4. Click "üöÄ Process Batch"
5. Review summary and download CSV

**CSV Format**:
```csv
filename,prediction,confidence,spoof_score,bonafide_score,duration
sample1.wav,BONAFIDE,95.23%,0.0477,0.9523,4.02s
sample2.wav,SPOOF,87.65%,0.8765,0.1235,3.15s
```

---

### Tab 3: ‚öñÔ∏è Model Comparison

**Purpose**: Compare predictions from different models side-by-side

**Features**:
- Load two models simultaneously
- Side-by-side score comparison
- Consensus/disagreement detection
- Comparative visualizations

**Outputs**:
- **Comparison Summary**: Both model predictions
- **Comparison Table**: Metric-by-metric differences
- **Bar Chart**: Visual score comparison
- **Consensus Analysis**: Agreement status and confidence differences

**Use Cases**:
- Model selection and validation
- Ensemble decision making
- Research: comparing AASIST vs XLS-R+SLS
- Quality assurance (multi-model agreement)

**Example Workflow**:
1. Upload audio file
2. Select Model 1 (e.g., AASIST)
3. Select Model 2 (e.g., XLS-R+SLS)
4. Click "‚öñÔ∏è Compare Models"
5. Analyze differences and consensus

**Interpretation**:
- ‚úÖ **Agreement**: Both models predict same class (high confidence)
- ‚ö†Ô∏è **Disagreement**: Models conflict (requires manual review)
- **Score Difference < 0.1**: Models essentially agree
- **Score Difference > 0.3**: Significant disagreement

---

### Tab 4: üìà Training Monitor

**Purpose**: Monitor ongoing model training in real-time

**Features**:
- Parse training log files
- Display progress percentage
- Show iteration speed and ETA
- Detect early stopping
- Auto-refresh option (planned)

**Outputs**:
- **Training Status**: Running/Completed/Early Stopped
- **Progress**: Current batch, total batches, percentage
- **Speed**: Iterations per second
- **ETA**: Estimated time remaining
- **Progress Bar**: Visual representation

**Use Cases**:
- Monitoring long-running training sessions
- Debugging training issues
- Estimating completion time
- Detecting early stopping events

**Example Workflow**:
1. Enter path to training log (e.g., `/path/to/training_output_LA.log`)
2. Click "üîç Check Status"
3. Review progress and ETA
4. Optionally enable auto-refresh

**Log File Requirements**:
- Must be a valid training output log
- Should contain tqdm progress bars or similar
- Default path: `/home/lab2208/Documents/deepfake_models/xls_r_sls/SLSforASVspoof-2021-DF/training_output_LA.log`

---

### Tab 5: üóÇÔ∏è Dataset Explorer

**Purpose**: Browse and analyze ASVspoof datasets

**Features**:
- Load protocol files automatically
- Filter by attack type (A07-A19)
- Filter by label (bonafide/spoof)
- View sample data
- Statistical analysis

**Outputs**:
- **Statistics**: Total samples, bonafide/spoof counts
- **Attack Distribution**: Per-attack-type breakdowns
- **Sample Table**: First 100 entries
- **Pie Charts**: Label and attack type distributions

**Use Cases**:
- Dataset exploration and understanding
- Attack type analysis
- Subset selection for experiments
- Data quality verification

**Example Workflow**:
1. Enter dataset path (e.g., `/path/to/ASVspoof2019_LA_train`)
2. Select attack type filter (optional)
3. Select label filter (optional)
4. Click "üîç Explore Dataset"
5. Review statistics and distributions

**Supported Datasets**:
- ASVspoof 2019 LA (Logical Access)
- ASVspoof 2021 LA
- Any dataset with ASVspoof protocol format

**Attack Types**:
- **A07-A19**: Various TTS and VC spoofing algorithms
- **`-`**: Bonafide speech (no attack)

---

### Tab 6: üî¨ Scientific Evaluation

**Purpose**: Run comprehensive benchmark evaluation with research metrics

**Status**: ‚ö†Ô∏è Stub implementation (integration with `comprehensive_eval.py` required)

**Planned Features**:
- Full ASVspoof evaluation on test sets
- EER (Equal Error Rate) computation
- min-tDCF calculation
- Per-attack EER breakdown
- DET curve generation
- ROC curve visualization
- LaTeX table export for papers

**Expected Outputs** (when complete):
- **Evaluation Report**: Detailed metrics summary
- **Metrics Table**: EER, t-DCF, per-attack EER
- **DET Curve**: Detection Error Tradeoff curve
- **Score Files**: CM scores for external processing

**Use Cases**:
- Reproducing paper results
- Benchmarking new models
- Scientific publication preparation
- Challenge submission preparation

**Integration TODO**:
```python
# Current stub:
def run_scientific_evaluation(model_path, dataset_protocol_path, device_selection="cuda"):
    return ("‚ö†Ô∏è Scientific evaluation requires full comprehensive_eval.py integration. Coming soon!", None, None)

# Needs:
# 1. Import comprehensive_eval functions
# 2. Run full evaluation pipeline
# 3. Generate DET/ROC curves
# 4. Export LaTeX tables
# 5. Compare with published baselines
```

---

## Architecture & Design

### Model Cache System

The interface uses a global model cache to avoid reloading models:

```python
MODEL_CACHE = {}

def get_model(model_path: str, device: str = "cuda"):
    """Get model from cache or load it."""
    if model_path not in MODEL_CACHE:
        MODEL_CACHE[model_path] = load_model(model_path, device)
    return MODEL_CACHE[model_path]
```

**Benefits**:
- Faster subsequent predictions
- Memory efficient (models loaded once)
- Supports model comparison without double loading

### Visualization Pipeline

All visualizations use matplotlib with consistent styling:

- **Waveform**: Time-domain representation
- **Spectrogram**: Frequency-domain analysis (STFT)
- **Prediction Charts**: Bar charts with color coding
  - Green (#2ecc71): Bonafide
  - Red (#e74c3c): Spoof
  - Gray (#95a5a6): Non-predicted class
- **Chunk Analysis**: Line plots for long audio

### Audio Processing

**Fixed Parameters**:
- Sample Rate: 16 kHz (resampled automatically)
- Chunk Length: 64,600 samples (4.0375 seconds)
- Chunk Overlap: 50% for long audio

**Supported Formats**:
- WAV, FLAC (lossless)
- MP3, OGG, M4A, OPUS (lossy)
- Stereo automatically converted to mono

---

## Performance Considerations

### GPU Memory Usage

| Model         | Parameters | Memory (batch=1) | Memory (batch=24) |
|---------------|------------|------------------|-------------------|
| AASIST        | 853K       | ~1 GB            | ~16 GB            |
| AASIST-L      | 85K        | ~500 MB          | ~8 GB             |
| XLS-R+SLS     | 340M       | ~14 GB           | N/A               |

**Recommendations**:
- Use AASIST-L for CPU or low-memory GPUs
- Single detection: Very fast (<1s per file)
- Batch processing: Linear scaling with file count

### Inference Speed

On NVIDIA RTX 4080:
- **Single file**: ~0.2-0.5 seconds
- **Batch (100 files)**: ~20-50 seconds
- **Speed**: ~2-5 files/second

On CPU (Intel i7):
- **Single file**: ~2-5 seconds
- **Batch (100 files)**: ~200-500 seconds

---

## Troubleshooting

### Common Issues

**1. Model not found**
```
‚úó Error loading model: [Errno 2] No such file or directory
```
**Solution**:
- Check model path in dropdown
- Ensure model file exists
- Use absolute paths

**2. CUDA out of memory**
```
RuntimeError: CUDA out of memory
```
**Solution**:
- Switch to CPU device
- Use AASIST-L (smaller model)
- Close other GPU applications

**3. Audio format not supported**
```
‚úó Error loading audio: [...]
```
**Solution**:
- Install additional codecs: `pip install librosa`
- Convert to WAV using ffmpeg
- Check file is not corrupted

**4. Gradio version issues**
```
AttributeError: module 'gradio' has no attribute 'Tabs'
```
**Solution**:
- Update Gradio: `pip install --upgrade gradio>=4.0`
- This interface requires Gradio 4.0+

**5. Training log not parsing**
```
‚ö†Ô∏è Could not parse training log
```
**Solution**:
- Ensure log file has tqdm progress output
- Check file path is correct
- Verify log file is not empty

---

## Advanced Usage

### Custom Model Integration

To add a new model:

1. **Train and save checkpoint** (`.pth` file)
2. **Place in model directory**:
   - `exp_result/` (for trained models)
   - `models/weights/` (for pretrained models)
   - `../xls_r_sls/SLSforASVspoof-2021-DF/models/` (for XLS-R+SLS)

3. **Model will appear automatically** in all dropdowns

### Batch Processing with Ground Truth

If you have ground truth labels, format CSV as:

```csv
filename,ground_truth,prediction,confidence
sample1.wav,bonafide,BONAFIDE,95.23%
sample2.wav,bonafide,SPOOF,87.65%
```

Then compute accuracy:
```python
df = pd.read_csv('batch_results.csv')
accuracy = (df['ground_truth'].str.upper() == df['prediction']).mean()
print(f"Accuracy: {accuracy*100:.2f}%")
```

### Programmatic Access

Use functions directly without GUI:

```python
from gradio_app_multitab import analyze_audio, process_batch, compare_models

# Single prediction
audio_tuple = (16000, audio_array)  # (sample_rate, audio)
result_text, waveform, spectrogram, prediction, chunk = analyze_audio(
    audio_tuple,
    model_selection="exp_result/LA_AASIST_ep100_bs24/weights/best.pth",
    device_selection="cuda"
)

# Batch processing
files = [file1, file2, file3]
summary, df, plot, csv_path = process_batch(files, model_path, "cuda")
```

---

## Scientific Validation

### Benchmark Results

**AASIST** (Jung et al., 2022):
- ASVspoof2019 LA: **0.83% EER**, **0.0275 min-tDCF**
- ASVspoof2021 LA: Competitive performance

**XLS-R + SLS** (Zhang et al., 2024):
- ASVspoof2021 LA: **2.87% EER** (target)
- ASVspoof2021 DF: **1.92% EER** (paper)

### Citations

When using this interface in research, cite:

```bibtex
@article{jung2022aasist,
  title={AASIST: Audio anti-spoofing using integrated spectro-temporal graph attention networks},
  author={Jung, Jee-weon and Heo, Hee-Soo and Tak, Hemlata and Shim, Hye-jin and Chung, Joon Son and Lee, Bong-Jin and Yu, Ha-Jin and Evans, Nicholas},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  year={2022}
}

@inproceedings{zhang2024xlsr,
  title={Audio Deepfake Detection with Self-supervised XLS-R and SLS Classifier},
  author={Zhang, Zhongyi and others},
  booktitle={ACM Multimedia},
  year={2024}
}
```

---

## Development Roadmap

### Completed ‚úÖ
- [x] Single audio detection with visualizations
- [x] Batch processing with CSV export
- [x] Model comparison (2 models)
- [x] Training monitor with log parsing
- [x] Dataset explorer with filters
- [x] Scientific evaluation stub

### In Progress üîÑ
- [ ] Auto-refresh for training monitor
- [ ] Scientific evaluation integration
- [ ] DET/ROC curve generation
- [ ] LaTeX table export

### Planned üìã
- [ ] Model ensemble (3+ models)
- [ ] Real-time audio streaming
- [ ] Attack type prediction (A07-A19 classification)
- [ ] Gradio Blocks caching for faster loads
- [ ] Docker deployment
- [ ] REST API mode

---

## System Requirements

### Minimum
- Python 3.7+
- 4GB RAM
- CPU-only (slow)

### Recommended
- Python 3.8+
- 16GB RAM
- NVIDIA GPU with 8GB+ VRAM
- CUDA 11.0+

### Dependencies

```txt
gradio>=4.0.0
torch>=1.6.0
numpy
pandas
matplotlib
scipy
soundfile
librosa (optional, for exotic formats)
resampy (optional, for resampling)
```

Install all:
```bash
pip install gradio torch numpy pandas matplotlib scipy soundfile
```

---

## Contributing

To extend the interface:

1. **Add new tab**: Create function following pattern
2. **Add to `create_interface()`**: Insert in `with gr.Tab()` block
3. **Test**: Run dry-run test
4. **Document**: Update this guide

**Code Style**:
- Functions follow `tab_function_name(inputs) -> (outputs)` pattern
- All functions return tuples matching Gradio outputs
- Error handling with try/except, return user-friendly messages
- Use matplotlib for all visualizations

---

## License & Acknowledgments

**Interface Code**: MIT License (if applicable)

**Models**:
- AASIST: Original authors (Jung et al.)
- XLS-R+SLS: Original authors (Zhang et al.)

**Datasets**:
- ASVspoof 2019/2021: Creative Commons License

**Built with**:
- Gradio (Apache 2.0)
- PyTorch (BSD)
- Matplotlib (PSF)

---

**Version**: 1.0.0
**Last Updated**: 2025-11-18
**Author**: Deepfake Detection Research Team
